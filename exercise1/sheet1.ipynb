{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before submitting\n",
    "1. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel\\Restart) and then **run all cells** (in the menubar, select Cell\\Run All).\n",
    "\n",
    "2. Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\\n\",\n",
    "\n",
    "3. After you submit the notebook more tests will be run on your code. The fact that no assertions fail on your computer localy does not guarantee that completed the exercise correctly.\n",
    "\n",
    "4. Please submit only the `*.ipynb` file.\n",
    "\n",
    "5. Make sure you fill in any place that says `YOUR CODE HERE` or \\\"YOUR ANSWER HERE\\\". Edit only between `YOUR CODE HERE` and `END YOUR CODE`.\n",
    "\n",
    "6. Make sure to use Python 3.6 at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info < (3, 6):\n",
    "    print(\"You are not using a modern enough version of Python. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a3debc5ec56dcacd18d88c1e8208840",
     "grade": true,
     "grade_id": "cell-e5951c7ec892701b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it\n",
    "\n",
    "# Use unittest asserts\n",
    "import unittest\n",
    "\n",
    "t = unittest.TestCase()\n",
    "from pprint import pprint\n",
    "\n",
    "# Helper assert function\n",
    "def assert_percentage(val):\n",
    "    t.assertGreaterEqual(val, 0.0, f\"Percentage ({val}) cannot be < 0\")\n",
    "    t.assertLessEqual(val, 1.0, f\"Percentage ({val}) cannot be > 1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20289a35a26a4e4743f4a3b57c562f26",
     "grade": false,
     "grade_id": "cell-dcb35deb0f0fe3e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Warm Ups\n",
    "\n",
    "Before starting the homework sheet we recommend you finish these warm-up tasks. They won't bring any points but should help you to get familiar with Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9a3bcc31f73bcf8a8942c6501930dfb",
     "grade": false,
     "grade_id": "cell-da302d4d2aa81a38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Function and types (0 P)\n",
    "\n",
    "Write a function using list comprehension that returns the types of list elements.\n",
    "\n",
    "* The function should be called `types_of`\n",
    "* The function expects a list as an input argument.\n",
    "* The function should return a list with the types of the given list elements.\n",
    "* Read the testing cell to understand how `types_of` is supposed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e2e34578cc015c168f95b29e486d937",
     "grade": false,
     "grade_id": "cell-8d004130189cffa5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def types_of(a:list):\n",
    "    list1=[type(x) for x in a]\n",
    "    return list1\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1da781e28dbf335a6b16e2da166ddac",
     "grade": true,
     "grade_id": "cell-e082a23baca66faf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test type_of_two function\n",
    "types = types_of([7, 0.7, \"hello\", True, (2, \"s\")])\n",
    "\n",
    "assert isinstance(types, list)\n",
    "t.assertEqual(types[0], int)\n",
    "t.assertEqual(types[1], float)\n",
    "t.assertEqual(types[2], str)\n",
    "t.assertEqual(types[3], bool)\n",
    "t.assertEqual(types[-1], tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83b4601ca0d89cf10b966ed3a28b9672",
     "grade": false,
     "grade_id": "cell-a1cca31a8ad0bffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Concatenation and enumerate (0 P)\n",
    "\n",
    "\n",
    "Concatenate the strings from the array 'animals' into one string.\n",
    "\n",
    "* Use: `counting +=` and string formatting.\n",
    "* Use `enumerate` to get the `i`th index.\n",
    "* The result should look as follows: `'0: mouse | 1: rabbit | 2: cat | 3: dog | '`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ddfc76de1665ae61767d57a96b383d7",
     "grade": false,
     "grade_id": "cell-0107276bf8cc8cb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "animals = [\"mouse\", \"rabbit\", \"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcb54a483ae4a753a6e3f93509882a3b",
     "grade": false,
     "grade_id": "cell-598f867f4109ac39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0: mouse |1: rabbit |2: cat |3: dog |\n"
     ]
    }
   ],
   "source": [
    "counting = \"|\"\n",
    "for i, animal in enumerate(animals):\n",
    "    # YOUR CODE HERE\n",
    "    counting+=f'{i}: {animal}'\n",
    "    counting+=\" |\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "print(counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "550c7835fbb04f9ca08ebc5181a6f218",
     "grade": true,
     "grade_id": "cell-cbf9e2c30017f8d7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test of the enumeration loop\n",
    "t.assertEqual(counting, \"|0: mouse |1: rabbit |2: cat |3: dog |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b99f341ff5892f09f3aa53bd2b4aba0",
     "grade": false,
     "grade_id": "cell-bc949de5bca7962f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### String formating (0 P)\n",
    "\n",
    "What does the following string formating result in?\n",
    "* Write the result of the string formating into the variables result1, result2, result3.\n",
    "* Example: `string0 = \"This is a {} string.\".format(\"test\")`\n",
    "* Example solution: `result0 = \"This is a test string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36fdcaad313c8bcb3b68acf78377422d",
     "grade": false,
     "grade_id": "cell-38b920b1680007a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# first string\n",
    "string1 = \"The sky is {}. {} words in front of {} random words create {} random sentence.\".format(\n",
    "    \"clear\", \"Random\", \"other\", 1\n",
    ")\n",
    "\n",
    "# second string\n",
    "a = \"irony\"\n",
    "b = \"anyone\"\n",
    "c = \"room\"\n",
    "\n",
    "string2 = f\"The {a} of the situation wasn't lost on {b} in the {c}.\"\n",
    "\n",
    "# third string\n",
    "string3 = f\"{7*10} * {9/3} with three digits after the floating point looks like this: {70*3 :.3f}.\"\n",
    "\n",
    "# fourth string\n",
    "string4 = \"   Hello World.   \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a811efecce09a51ce00090bf85a7e47",
     "grade": false,
     "grade_id": "cell-13d9b5efd9dd60e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World.\n"
     ]
    }
   ],
   "source": [
    "print(string4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9966e45d8ba27daa18b2e7a561b6450d",
     "grade": false,
     "grade_id": "cell-ab79852811b12118",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "result1 = \"The sky is clear. Random words in front of other random words create 1 random sentence.\"\n",
    "result2 = \"The irony of the situation wasn't lost on anyone in the room.\"\n",
    "result3 = \"70 * 3.0 with three digits after the floating point looks like this: 210.000.\"\n",
    "result4 = \"Hello World.\"\n",
    "string5 = \"hello\"\n",
    "result5 = \"hello\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a49648e24b25ad98c33deb5b7ed055c5",
     "grade": true,
     "grade_id": "cell-09a4a5a04b6d9098",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test the string results\n",
    "t.assertEqual(string1, result1)\n",
    "t.assertEqual(string2, result2)\n",
    "t.assertEqual(string3, result3)\n",
    "t.assertEqual(string4, result4)\n",
    "t.assertEqual(string5, result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e924a8efe0e69f06915151283945546",
     "grade": false,
     "grade_id": "cell-b2b789b02a0b4bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet 1: Python Basics\n",
    "\n",
    "This first  exercise sheet tests the basic functionalities of the Python programming language in the context of a simple prediction task. We consider the problem of predicting health risk of subjects from personal data and habits. We first use for this task a decision tree.\n",
    "\n",
    "![](tree.png)\n",
    "\n",
    "Make sure that you have downloaded the `tree.png` file from ISIS. For this exercise sheet, you are required to use only pure Python, and to not import any module, including `Numpy`. Next week are going to implement the nearest neighbor part of this exercise sheet using `Numpy` 😉."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f564e12d46d132b419ae75e9a1b1f46",
     "grade": false,
     "grade_id": "cell-33557bd5b8af8865",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Classifying a single instance (15 P)\n",
    "\n",
    "* In this sheet we will represent patient info as a tuple.\n",
    "* Implement the function `decision` that takes as input a tuple containing values for attributes (smoker,age,diet), and computes the output of the decision tree. Should return either `'less'` or `'more'`. No other outputs are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5df4a3907c97f42630ec730c6971ad1",
     "grade": false,
     "grade_id": "cell-b66d7278bc313c94",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decision(x: tuple) -> str:\n",
    "    \"\"\"\n",
    "    This function implements the decision tree represented in the above image. As input the function \n",
    "    receives a tuple with three values that represent some information about a patient.\n",
    "    Args:\n",
    "        x (tuple): Input tuple containing exactly three values. The first element represents \n",
    "        a patient is a smoker this value will be 'yes'. All other values represent that \n",
    "        the patient is not a smoker. The second element represents the age of a patient\n",
    "        in years as an integer. The last element represents the diet of a patient.\n",
    "        If a patient has a good diet this string will be 'good'. All other\n",
    "            values represent that the patient has a poor diet.\n",
    "    Returns:\n",
    "        string: A string that has either the value 'more' or 'less'. \n",
    "        No other return value is valid.\n",
    "                        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if x[0] == \"yes\":\n",
    "        if x[1] < 29.5:\n",
    "            return \"less\"\n",
    "        else:\n",
    "            return \"more\"\n",
    "    else:\n",
    "        if x[2] == \"good\":\n",
    "            return \"less\"\n",
    "        else:\n",
    "            return \"more\"\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9eae9d6986516961671f4a92c14ccf6",
     "grade": true,
     "grade_id": "cell-c31b80471db3132f",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision(('yes', 31, 'good')) --> more\n",
      "decision(('yes', 29, 'poor')) --> less\n"
     ]
    }
   ],
   "source": [
    "# Test decision function\n",
    "\n",
    "# Test expected 'more'\n",
    "x = (\"yes\", 31, \"good\")\n",
    "output = decision(x)\n",
    "print(f\"decision({x}) --> {output}\")\n",
    "t.assertIsInstance(output, str)\n",
    "t.assertEqual(output, \"more\")\n",
    "\n",
    "# Test expected 'less'\n",
    "x = (\"yes\", 29, \"poor\")\n",
    "output = decision(x)\n",
    "print(f\"decision({x}) --> {output}\")\n",
    "t.assertIsInstance(output, str)\n",
    "t.assertEqual(output, \"less\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a002cdeb30f449ded2d741a0cecaac82",
     "grade": true,
     "grade_id": "cell-a706e6de3303d3e7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01fc86ffb048b4c11a92662a3b96edda",
     "grade": false,
     "grade_id": "cell-f99e2c2efcd83d8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reading a dataset from a text file (10 P)\n",
    "\n",
    "The file `health-test.txt` contains several fictious records of personal data and habits. We split this task into two parts. In the first part, we assume that we have read a line from the file and can now process it. In the second function we load the file and process each line.\n",
    "\n",
    "* Read the file automatically using the methods introduced during the lecture.\n",
    "* Represent the dataset as a list of tuples. Make sure that the tuples have the same format as in the previous task, e.g. `('yes', 31, 'good')`.\n",
    "* Make sure that you close the file after you have opened it and read its content. If you use a `with` statement then you don't have to worry about closing the file.\n",
    "\n",
    "**Notes**: \n",
    "* Values read from files are always strings.\n",
    "* Each line contains a newline `\\n` character at the end\n",
    "* If you are using Windows as your operating system, refrain from opening any text files using Notepad. It will remove any linebreaks `\\n`. You should inspect the files using the Jupyter text editor or any other modern text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00aa0b16846bd8fc2eb0b5577fb29213",
     "grade": false,
     "grade_id": "cell-c1a8bc4c0e4ccb26",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_test(line: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Takes a line from the file, including a newline, and parses it into a patient tuple\n",
    "    \n",
    "    Args:\n",
    "        line (str): A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        tuple: A tuple representing a patient \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    line = line.rstrip()\n",
    "    patient = (line.split(\",\"))\n",
    "    patient = (patient[0],int(patient[1]),patient[2])\n",
    "    return patient\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13f325537ae888e579a5977d9e00dcdf",
     "grade": true,
     "grade_id": "cell-4e1f7ad1e66b3121",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', 23, 'good')\n"
     ]
    }
   ],
   "source": [
    "x = \"yes,23,good\\n\"\n",
    "parsed_line = parse_line_test(x)\n",
    "print(parsed_line)\n",
    "t.assertIsInstance(parsed_line, tuple)\n",
    "t.assertEqual(len(parsed_line), 3)\n",
    "t.assertIsInstance(parsed_line[1], int)\n",
    "t.assertNotIn(\"\\n\", parsed_line[-1], \"Are you handling line breaks correctly?\")\n",
    "t.assertEqual(parsed_line[-1], \"good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff88dfc864c57b2eb8238574d968d84e",
     "grade": true,
     "grade_id": "cell-0ed341eaf90d76a6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5432bb0d5684bd1304defa1683776d2f",
     "grade": false,
     "grade_id": "cell-844c38f934d4a3ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gettest() -> list:\n",
    "    \"\"\"\n",
    "    Opens the `health-test.txt` file and parses it \n",
    "    into a list of patient tuples. You are encouraged to use \n",
    "    the `parse_line_test` function but it is not necessary to do so.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of patient tuples\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data = []\n",
    "    with open('./health-test.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            parsed_line = parse_line_test(line)\n",
    "\n",
    "            data.append(tuple(parsed_line))\n",
    "    return data\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3272a62886b113d328e28dede8f89973",
     "grade": true,
     "grade_id": "cell-ab1b01fcaac26cd5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 21, 'poor'),\n",
      " ('no', 50, 'good'),\n",
      " ('no', 23, 'good'),\n",
      " ('yes', 45, 'poor'),\n",
      " ('yes', 51, 'good'),\n",
      " ('no', 60, 'good'),\n",
      " ('no', 15, 'poor'),\n",
      " ('no', 18, 'good')]\n"
     ]
    }
   ],
   "source": [
    "testset = gettest()\n",
    "pprint(testset)\n",
    "t.assertIsInstance(testset, list)\n",
    "t.assertEqual(len(testset), 8)\n",
    "t.assertIsInstance(testset[0], tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a5d31521d79fb22447e17337cc2aa8",
     "grade": true,
     "grade_id": "cell-42b0a5cad68fc15a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the decision tree to the dataset (15 P)\n",
    "\n",
    "* Apply the decision tree to all points in the dataset, and return the ratio of them that are classified as \"more\".\n",
    "* A ratio is a value in [0-1]. So if out of 50 data points 15 return `\"more\"` the value that should be returned is `0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ddeb9715bfedad398b5b97212a54a53",
     "grade": false,
     "grade_id": "cell-6703ef98e2b5c93b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset(dataset: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the percentage of datapoints for which the\n",
    "    decision function evaluates to `'more'` for a given dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): A list of patient tuples\n",
    "    \n",
    "    Returns:\n",
    "        float: The percentage of data points which are evaluated to `'more'`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    j=0\n",
    "    for i in dataset:\n",
    "        if decision(i) == \"more\":\n",
    "            j+=1\n",
    "        ratio = j/len(dataset)\n",
    "    return ratio\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea88a8261264b575a90114301d142b02",
     "grade": true,
     "grade_id": "cell-c13a0b23c9faba52",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio --> 0.375\n"
     ]
    }
   ],
   "source": [
    "ratio = evaluate_testset(gettest())\n",
    "print(f\"ratio --> {ratio}\")\n",
    "t.assertIsInstance(ratio, float)\n",
    "assert_percentage(ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from examples (10 P)\n",
    "\n",
    "Suppose that instead of relying on a fixed decision tree, we would like to use a data-driven approach where data points are classified based on a set of training observations manually labeled by experts. Such labeled dataset is available in the file `health-train.txt`. The first three columns have the same meaning than for `health-test.txt`, and the last column corresponds to the labels.\n",
    "\n",
    "* Read the `health-train.txt` file and convert it into a list of pairs. The first element of each pair is a triplet of attributes, and the second element is the label.\n",
    "* Similarlly to the previous exercise we split the task into two parts. The first involves processing each line individually. The second handles opening the file and processing all lines of the file\n",
    "\n",
    "**Note**: A triplet is a tuple that contains exactly three values, a pair is a tuple that contains exactly two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b3afb0f84353ba6bea6c32062e316b7",
     "grade": false,
     "grade_id": "cell-fc38ed11fee6fbeb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_train(line: str) -> tuple:\n",
    "    \"\"\"\n",
    "    This function works similarly to the `parse_line_test` function.\n",
    "    It parses a line of the `health-train.txt` file into a tuple that \n",
    "    contains a patient tuple and a label.\n",
    "    \n",
    "    Args:\n",
    "        line (str): A line from the `health-train.txt`\n",
    "    \n",
    "    Returns: \n",
    "        tuple: A tuple that contains a patient tuple and a label as a string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    line = line.rstrip()\n",
    "    patient = (line.split(\",\"))\n",
    "    pair1 = (patient[0], int(patient[1]), patient[2])\n",
    "    pair = (pair1,patient[3])\n",
    "    return pair\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d853d0f3f340cb19738db737d391ec9",
     "grade": true,
     "grade_id": "cell-b97620858b167c0d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yes', 67, 'poor'), 'more')\n"
     ]
    }
   ],
   "source": [
    "x = \"yes,67,poor,more\\n\"\n",
    "parsed_line = parse_line_train(x)\n",
    "print(parsed_line)\n",
    "\n",
    "t.assertIsInstance(parsed_line, tuple)\n",
    "t.assertEqual(len(parsed_line), 2)\n",
    "\n",
    "data, label = parsed_line\n",
    "\n",
    "t.assertIsInstance(data, tuple)\n",
    "t.assertEqual(len(data), 3)\n",
    "t.assertEqual(data[1], 67)\n",
    "\n",
    "t.assertIsInstance(label, str)\n",
    "t.assertNotIn(\"\\n\", label, \"Are you handling line breaks correctly?\")\n",
    "t.assertEqual(label, \"more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d360bdd66c4f65216fb37dc1c36f30a",
     "grade": true,
     "grade_id": "cell-ced9925599b5dd99",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b2df03ae19926672d9237303700301a",
     "grade": false,
     "grade_id": "cell-183f0bbeecd179c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gettrain() -> list:\n",
    "    \"\"\"\n",
    "    Opens the `health-train.txt` file and parses it into \n",
    "    a list of patient tuples accompanied by their respective label. \n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples comprised of a patient tuple and a label\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data_train = []\n",
    "    with open('./health-train.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            parsed_line = parse_line_train(line)\n",
    "            data_train.append(tuple(parsed_line))\n",
    "    return data_train\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f87b6b544cb271be54229ddb60b58c",
     "grade": true,
     "grade_id": "cell-a3d593f232e0403a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('yes', 54, 'good'), 'less'),\n",
      " (('no', 55, 'good'), 'less'),\n",
      " (('no', 26, 'good'), 'less'),\n",
      " (('yes', 40, 'good'), 'more'),\n",
      " (('yes', 25, 'poor'), 'less'),\n",
      " (('no', 13, 'poor'), 'more'),\n",
      " (('no', 15, 'good'), 'less'),\n",
      " (('no', 50, 'poor'), 'more'),\n",
      " (('yes', 33, 'good'), 'more'),\n",
      " (('no', 35, 'good'), 'less'),\n",
      " (('no', 41, 'good'), 'less'),\n",
      " (('yes', 30, 'poor'), 'more'),\n",
      " (('no', 39, 'poor'), 'more'),\n",
      " (('no', 20, 'good'), 'less'),\n",
      " (('yes', 18, 'poor'), 'less'),\n",
      " (('yes', 55, 'good'), 'more')]\n"
     ]
    }
   ],
   "source": [
    "trainset = gettrain()\n",
    "pprint(trainset)\n",
    "t.assertIsInstance(trainset, list)\n",
    "t.assertEqual(len(trainset), 16)\n",
    "first_datapoint = trainset[0]\n",
    "t.assertIsInstance(first_datapoint, tuple)\n",
    "t.assertIsInstance(first_datapoint[0], tuple)\n",
    "t.assertIsInstance(first_datapoint[1], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1745c8c6c934e4d3fb0ac74538015ad",
     "grade": true,
     "grade_id": "cell-7ab8ef2c931d69c1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classifier (25 P)\n",
    "\n",
    "We consider the nearest neighbor algorithm that classifies test points following the label of the nearest neighbor in the training data. You can read more about Nearest neighbor classifiers [here](http://www.robots.ox.ac.uk/~dclaus/digits/neighbour.htm). For this, we need to define a distance function between data points. We define it to be\n",
    "\n",
    "`distance(a, b) = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])`\n",
    "\n",
    "^this is not valid python code\n",
    "\n",
    "where `a` and `b` are two tuples corrsponding to the attributes of two data points.\n",
    "\n",
    "* Implement the distance function.\n",
    "* Implement the function that retrieves for a test point the nearest neighbor in the training set, and classifies the test point accordingly (i.e. returns the label of the nearest data point).\n",
    "\n",
    "**Hint**: You can use the special `infinity` floating point value with `float('inf')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa76a4b85e7e0161a628f43223cde1e4",
     "grade": false,
     "grade_id": "cell-671ea24ec8a11241",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def distance(a: tuple, b: tuple) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the distance between two data points (patient tuples)\n",
    "    Args:\n",
    "        a, b (tuple): Two patient tuples for which we want to calculate the distance\n",
    "    Returns:\n",
    "        float: The distance between a, b according to the above formula\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    Distance = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])\n",
    "    return Distance\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7bd46b9f7ea55bdf131cdf91a1240e0",
     "grade": true,
     "grade_id": "cell-5929fce6ffc8ca0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance(('yes', 34, 'poor'), ('yes', 51, 'good')) --> 1.1156\n"
     ]
    }
   ],
   "source": [
    "# Test distance\n",
    "x1 = (\"yes\", 34, \"poor\")\n",
    "x2 = (\"yes\", 51, \"good\")\n",
    "dist = distance(x1, x2)\n",
    "print(f\"distance({x1}, {x2}) --> {dist}\")\n",
    "expected_dist = 1.1156\n",
    "t.assertAlmostEqual(dist, expected_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3866d76d49cb35ab5cc87229ecf5d50",
     "grade": true,
     "grade_id": "cell-8dc0c32bc78d1e62",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c16761b18bc20488009d20edc3ca836e",
     "grade": false,
     "grade_id": "cell-e2ffaa5484ac1886",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def neighbor(x: tuple, trainset: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns the label of the nearest data point in trainset to x.\n",
    "    If x is `('no', 30, 'good')` and the nearest data point in trainset\n",
    "    is `('no', 31, 'good')` with label `'less'` then `'less'` will be returned \n",
    "    \n",
    "    Args: \n",
    "        x (tuple): The data point for which we want to find the nearest neighbor\n",
    "        trainset (list): A list of tuples with patient tuples and a label\n",
    "        \n",
    "    Returns: \n",
    "        str: The label of the nearest data point in the trainset. Can only be 'more' or 'less'\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    a = []\n",
    "    for b in trainset:\n",
    "        a.append(distance(x,b[0]))\n",
    "        c = min(a)\n",
    "    print(a)\n",
    "    print(c)\n",
    "    for idx, n in enumerate(trainset):\n",
    "        if c == distance(x, n[0]):\n",
    "            pre = n[1]\n",
    "            print(n)\n",
    "    return pre\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bffb2cd902697f310fa963e7ce38b603",
     "grade": true,
     "grade_id": "cell-a36122337853f195",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2116, 1.2304, 1.01, 0.0324, 1.0144, 2.1296, 1.1024, 2.1444, 0.0016, 1.0064, 1.04, 1.0004, 2.0256, 1.0484, 1.0676, 0.2304]\n",
      "0.0016\n",
      "(('yes', 33, 'good'), 'more')\n",
      "prediction --> more\n"
     ]
    }
   ],
   "source": [
    "# Test neighbor\n",
    "x = (\"yes\", 31, \"good\")\n",
    "prediction = neighbor(x, gettrain())\n",
    "print(f\"prediction --> {prediction}\")\n",
    "expected = \"more\"\n",
    "t.assertEqual(prediction, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d16b55bb994bf1f1b355e07a0040b0",
     "grade": true,
     "grade_id": "cell-cbf6ddfbfaab7875",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply both the decision tree and nearest neighbor classifiers on the test set, and return the list of data point(s) for which the two classifiers disagree, and with which probability it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abe9c75a2c8157a14b336bb92b079adb",
     "grade": false,
     "grade_id": "cell-8dbf7da153f3d797",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compare_classifiers(trainset: list, testset: list) -> float:\n",
    "    \"\"\"\n",
    "    This function compares the two classification methods by finding all the datapoints for which \n",
    "    the methods disagree.\n",
    "    \n",
    "    Args:\n",
    "        trainset (list): The training set used in the nearest neighbour classfier.\n",
    "        testset (list): Contains the elements which will be used to compare the \n",
    "            decision tree and nearest neighbor classification methods.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list containing all the data points which yield different results for the two\n",
    "            classification methods.\n",
    "        float: The percentage of data points for which the two methods disagree.\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    decisionset = testset\n",
    "    neighborset = trainset\n",
    "    count = 0\n",
    "    disagree = []\n",
    "    for patient in decisionset:\n",
    "        if decision(patient) != neighbor(patient,neighborset):\n",
    "            #print(patient)\n",
    "            disagree.append(patient)\n",
    "            #print(disagree)\n",
    "            count += 1\n",
    "            #print(count)\n",
    "    percentage = count / len(testset)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return disagree, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ff0b92f597a12d939f935061b615fe6",
     "grade": true,
     "grade_id": "cell-3b55f7e89ad4dfeb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4356, 2.4624, 2.01, 1.1444, 0.0064, 1.0256, 2.0144, 1.3364, 1.0576, 2.0784000000000002, 2.16, 0.0324, 1.1296, 2.0004, 0.0036, 1.4624000000000001]\n",
      "0.0036\n",
      "(('yes', 18, 'poor'), 'less')\n",
      "[1.0064, 0.010000000000000002, 0.2304, 1.04, 2.25, 1.5476, 0.48999999999999994, 1.0, 1.1156, 0.09, 0.0324, 2.16, 1.0484, 0.36, 2.4096, 1.01]\n",
      "0.010000000000000002\n",
      "(('no', 55, 'good'), 'less')\n",
      "[1.3844, 0.4096, 0.0036, 1.1156, 2.0016, 1.04, 0.0256, 1.2916, 1.04, 0.0576, 0.1296, 2.0196, 1.1024, 0.0036, 2.01, 1.4096]\n",
      "0.0036\n",
      "(('no', 26, 'good'), 'less')\n",
      "(('no', 20, 'good'), 'less')\n",
      "[1.0324, 2.04, 2.1444, 1.01, 0.16000000000000003, 1.4096, 2.36, 1.01, 1.0576, 2.04, 2.0064, 0.09, 1.0144, 2.25, 0.2916, 1.04]\n",
      "0.09\n",
      "(('yes', 30, 'poor'), 'more')\n",
      "[0.0036, 1.0064, 1.25, 0.0484, 1.2704, 2.5776, 1.5184, 2.0004, 0.1296, 1.1024, 1.04, 1.1764, 2.0576, 1.3844, 1.4356, 0.0064]\n",
      "0.0036\n",
      "(('yes', 54, 'good'), 'less')\n",
      "[1.0144, 0.010000000000000002, 0.4624000000000001, 1.1600000000000001, 2.49, 1.8836, 0.81, 1.04, 1.2916, 0.25, 0.1444, 2.36, 1.1764, 0.6400000000000001, 2.7056, 1.01]\n",
      "0.010000000000000002\n",
      "(('no', 55, 'good'), 'less')\n",
      "[2.6084, 1.6400000000000001, 1.0484, 2.25, 1.04, 0.0016, 1.0, 0.48999999999999994, 2.1296, 1.1600000000000001, 1.2704, 1.09, 0.2304, 1.01, 1.0036, 2.64]\n",
      "0.0016\n",
      "(('no', 13, 'poor'), 'more')\n",
      "[1.5184, 0.5476, 0.0256, 1.1936, 2.0196, 1.01, 0.0036, 1.4096, 1.09, 0.11560000000000002, 0.2116, 2.0576, 1.1764, 0.0016, 2.0, 1.5476]\n",
      "0.0016\n",
      "(('no', 20, 'good'), 'less')\n"
     ]
    }
   ],
   "source": [
    "# Test compare_classifiers\n",
    "disagree, ratio = compare_classifiers(gettrain(), gettest())\n",
    "t.assertIsInstance(disagree, list)\n",
    "t.assertIsInstance(disagree[0], tuple)\n",
    "assert_percentage(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem of simple nearest neighbors is that one needs to compare the point to predict to all data points in the training set. This can be slow for datasets of thousands of points or more. Alternatively, some classifiers train a model first, and then use it to classify the data.\n",
    "\n",
    "## Nearest mean classifier (25 P)\n",
    "\n",
    "We consider one such trainable model, which operates in two steps:\n",
    "\n",
    "1. Compute the average point for each class\n",
    "2. Classify new points to be of the class whose average point is nearest to the point to predict.\n",
    "\n",
    "For this classifier, we convert the attributes smoker and diet to real values (for smoker: yes=1.0 and no=0.0, and for diet: good=0.0 and poor=1.0), and use the modified distance function:\n",
    "\n",
    "`distance(a,b) = (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2`\n",
    "\n",
    "Age will also from now on be represented as a `float`. The new data points will be referred to as numerical patient tuples. \n",
    "\n",
    "We adopt an object-oriented approach for building this classifier.\n",
    "\n",
    "* Implement the `gettrain_num` function that will load the training dataset from the `health-train.txt` file and parse each line to a numerical patient tuple with its label. You can still follow the same structure that we used before (i.e. using a `parse_line_...` function), however, it is not required for this exercise. Only the `gettrain_num` function will be tested.\n",
    "\n",
    "\n",
    "* Implement the new distance function.\n",
    "\n",
    "\n",
    "* Implement the methods `train` and `predict` of the class `NearestMeanClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7cd11ec7f33664c398b46898c772871",
     "grade": false,
     "grade_id": "cell-efadd1b300bd22ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_train_num(line: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Takes a line from the file `health-train.txt`, including a newline, \n",
    "    and parses it into a numerical patient tuple\n",
    "    \n",
    "    Args:\n",
    "        line (str): A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        tuple: A numerical patient\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    line = line.rstrip()\n",
    "    patient = (line.split(\",\"))\n",
    "    #print(patient)\n",
    "    if patient[0] == \"yes\":\n",
    "        patient[0] = 1.0\n",
    "    elif patient[0] == \"no\":\n",
    "        patient[0] = 0.0\n",
    "    if patient[2] == \"good\":\n",
    "        patient[2] = 0.0\n",
    "    elif patient[2] == \"poor\":\n",
    "        patient[2] = 1.0\n",
    "    pair1 = (patient[0], float(patient[1]), patient[2])\n",
    "    pair = (pair1, patient[3])\n",
    "    return pair\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "\n",
    "def gettrain_num() -> list:\n",
    "    \"\"\"\n",
    "    Parses the `health-train.txt` file into numerical patient tuples\n",
    "    \n",
    "    Returns: \n",
    "        list: A list of tuples containing numerical patient tuples and their labels\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data_train = []\n",
    "    with open('./health-train.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            parsed_line = parse_line_train_num(line)\n",
    "            data_train.append(tuple(parsed_line))\n",
    "    return data_train\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e258d862a418a7d3606d5cdb3742f89",
     "grade": true,
     "grade_id": "cell-b8a19b27d4c7de88",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_datapoint --> ((1.0, 54.0, 0.0), 'less')\n"
     ]
    }
   ],
   "source": [
    "# Test gettrain_num\n",
    "trainset_num = gettrain_num()\n",
    "t.assertIsInstance(trainset_num, list)\n",
    "first_datapoint = trainset_num[0]\n",
    "print(f\"first_datapoint --> {first_datapoint}\")\n",
    "t.assertIsInstance(first_datapoint[0], tuple)\n",
    "t.assertIsInstance(first_datapoint[0][0], float)\n",
    "t.assertIsInstance(first_datapoint[0][1], float)\n",
    "t.assertIsInstance(first_datapoint[0][2], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90ffe9aae095119e420e54e50c3c355d",
     "grade": true,
     "grade_id": "cell-789233fd9f800e77",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9f824dd41abb5e250e704e561935987",
     "grade": false,
     "grade_id": "cell-d35765538d512a1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def distance_num(a: tuple, b: tuple) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the distance between two data points (numerical patient tuples)\n",
    "    Args:\n",
    "        a, b (tuple): Two numerical patient tuples for which \n",
    "            we want to calculate the distance\n",
    "    Returns:\n",
    "        float: The distance between a, b according to the above formula\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    Distance = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])\n",
    "    return Distance\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc90185cabcbc24c94930d307130726d",
     "grade": true,
     "grade_id": "cell-de4d8b77145f3bff",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist --> 2.1296\n"
     ]
    }
   ],
   "source": [
    "x1 = (1.0, 23.0, 0.0)\n",
    "x2 = (0.0, 41.0, 1.0)\n",
    "dist = distance_num(x1, x2)\n",
    "print(f\"dist --> {dist}\")\n",
    "t.assertIsInstance(dist, float)\n",
    "expected_dist = 2.1296\n",
    "t.assertAlmostEqual(dist, expected_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b22e3ca4e043abde7cba27758fa484",
     "grade": true,
     "grade_id": "cell-28628e7373da18f2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f1dfae1e953485403891e32f224ec2e",
     "grade": false,
     "grade_id": "cell-e0b339bfd0fcc16c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NearestMeanClassifier:\n",
    "    \"\"\"\n",
    "    Represents a NearestMeanClassifier.\n",
    "    \n",
    "    When an instance is trained a dataset is provided and the mean for each class is calculated.\n",
    "    During prediction the instance compares the datapoint to each class mean (not all datapoints) \n",
    "    and returns the label of the class mean to which the datapoint is closest to.\n",
    "    \n",
    "    Instance Attributes:\n",
    "        more (tuple): A tuple representing the mean of every 'more' data-point in the dataset\n",
    "        less (tuple): A tuple representing the mean of every 'less' data-point in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.more = None\n",
    "        self.less = None\n",
    "\n",
    "    def train(self, dataset: list):\n",
    "        \"\"\"\n",
    "        Calculates the class means for a given dataset and stores \n",
    "        them in instance attributes more, less. \n",
    "        Args:\n",
    "            dataset (list): A list of tuples each of them containing a numerical patient tuple and its label\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        a = 0\n",
    "        b = 0\n",
    "        c = 0\n",
    "        d = 0\n",
    "        e = 0\n",
    "        f = 0\n",
    "        m = 0\n",
    "        n = 0\n",
    "        for i in dataset:\n",
    "            if i[1] == \"more\":\n",
    "                a += i[0][0]\n",
    "                b += i[0][1]\n",
    "                c += i[0][2]\n",
    "                m +=1\n",
    "            elif i[1] == \"less\":\n",
    "                d += i[0][0]\n",
    "                e += i[0][1]\n",
    "                f += i[0][2]\n",
    "                n += 1\n",
    "        tupm = [a/m,b/m,c/m]\n",
    "        tupn = [d/n,e/n,f/n]\n",
    "        self.more = tuple(tupm)\n",
    "        self.less = tuple(tupn)\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x: tuple) -> str:\n",
    "        \"\"\"\n",
    "        Returns a prediction/label for numeric patient tuple x. \n",
    "        The classifier compares the given data point to the mean \n",
    "        class tuples of each class and returns the label of the\n",
    "        class to which x is the closest to (according to our \n",
    "        distance function).\n",
    "        \n",
    "        Args: \n",
    "            x (tuple): A numerical patient tuple for which we want a prediction\n",
    "            \n",
    "        Returns:\n",
    "            str: The predicted label\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        Distancem = distance_num(x,self.more)\n",
    "        Distancen = distance_num(x,self.less)\n",
    "        #Distancem = (x[0] != self.more[0]) + ((x[1] - self.more[1]) / 50.0) ** 2 + (x[2] != self.more[2])\n",
    "        #Distancen = (x[0] != self.less[0]) + ((x[1] - self.less[1]) / 50.0) ** 2 + (x[2] != self.less[2])\n",
    "        '''\n",
    "        if Distancem <= Distancen:\n",
    "            label = \"more\"\n",
    "        else:\n",
    "            label = \"less\"\n",
    "        return label\n",
    "        '''\n",
    "        a = min(Distancem,Distancen)\n",
    "        if a == Distancem:\n",
    "            label = \"more\"\n",
    "        else:\n",
    "            label = \"less\"\n",
    "        return label\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "\n",
    "    def __repr__(self):\n",
    "        more = tuple(round(m, 3) for m in self.more) if self.more else self.more\n",
    "        less = tuple(round(l, 3) for l in self.less) if self.less else self.less\n",
    "        return f\"NearestMeanClassfier(more: {more}, less: {less})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate the `NearestMeanClassifier`, train it on the training data, and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40526d85bd928071838324915a2a3f4d",
     "grade": false,
     "grade_id": "cell-5f7f00ee83c94703",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_and_train(trainset_num: list) -> NearestMeanClassifier:\n",
    "    \"\"\"\n",
    "    Instantiates the `NearestMeanClassifier`, trains it on the\n",
    "    `trainset_num` dataset and returns it.\n",
    "    \n",
    "    Args: \n",
    "        trainset_num (list): A list of numerical patient tuples with their respective labels\n",
    "    \n",
    "    Returns:\n",
    "        NearestMeanClassifier: A NearestMeanClassifier trained on `trainset_num`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    c = NearestMeanClassifier()\n",
    "    c.train(trainset_num)\n",
    "    return c\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef6ea291d2f7c0b69ac77e195178f09e",
     "grade": true,
     "grade_id": "cell-415891bde4cbde19",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestMeanClassfier(more: (0.571, 37.143, 0.571), less: (0.333, 32.111, 0.222))\n"
     ]
    }
   ],
   "source": [
    "# Test build_and_train\n",
    "classifier = build_and_train(gettrain_num())\n",
    "print(classifier)\n",
    "t.assertIsInstance(classifier, NearestMeanClassifier)\n",
    "\n",
    "t.assertIsNotNone(\n",
    "    classifier.more,\n",
    "    \"Did you train the classifier? \\\n",
    "Did you store the mean vector for the 'more' class?\",\n",
    ")\n",
    "t.assertIsNotNone(\n",
    "    classifier.less,\n",
    "    \"Did you train the classifier? \\\n",
    "Did you store the mean vector for the 'less' class?\",\n",
    ")\n",
    "\n",
    "t.assertIsInstance(classifier.more, tuple)\n",
    "t.assertIsInstance(classifier.less, tuple)\n",
    "\n",
    "t.assertEqual(round(classifier.more[1]), 37)\n",
    "t.assertEqual(round(classifier.less[1]), 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "537c8f2b10eeeb376715afb96f2a8e63",
     "grade": true,
     "grade_id": "cell-ca2d0921e96ede25",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. Do NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the test dataset into memory as a list of numerical patient tuples\n",
    "* Predict the test data using the nearest mean classifier and return all test examples for which all three classifiers (decision tree, nearest neighbor and nearest mean) agree.\n",
    "\n",
    "**Note**: Be careful that the `NearestMeanClassifier` expects the dataset in a different form, compared to the other two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4239163b53cf6f6f2164db8b3fa2eec5",
     "grade": false,
     "grade_id": "cell-f37f3035a32a8f85",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gettest_num() -> list:\n",
    "    \"\"\"\n",
    "    Parses the `health-test.txt` file into numerical patient tuples\n",
    "    \n",
    "    Returns: \n",
    "        list: A list containing numerical patient tuples, loaded from `health-test.txt`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    def parse_line_test_num(line: str) -> tuple:\n",
    "        line = line.rstrip()\n",
    "        patient = (line.split(\",\"))\n",
    "        if patient[0] == \"yes\":\n",
    "            patient[0] = 1.0\n",
    "        elif patient[0] == \"no\":\n",
    "            patient[0] = 0.0\n",
    "        if patient[2] == \"good\":\n",
    "            patient[2] = 0.0\n",
    "        elif patient[2] == \"poor\":\n",
    "            patient[2] = 1.0\n",
    "        pair1 = (patient[0], float(patient[1]), patient[2])\n",
    "        return pair1\n",
    "    data_train = []\n",
    "    with open('./health-test.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            parsed_line = parse_line_test_num(line)\n",
    "            data_train.append(tuple(parsed_line))\n",
    "    return data_train\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c340b09ad8ffbd109d302c8e4f6234a2",
     "grade": true,
     "grade_id": "cell-f3656461c994dc3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 21.0, 1.0),\n",
      " (0.0, 50.0, 0.0),\n",
      " (0.0, 23.0, 0.0),\n",
      " (1.0, 45.0, 1.0),\n",
      " (1.0, 51.0, 0.0),\n",
      " (0.0, 60.0, 0.0),\n",
      " (0.0, 15.0, 1.0),\n",
      " (0.0, 18.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "testset_num = gettest_num()\n",
    "pprint(testset_num)\n",
    "t.assertIsInstance(testset_num, list)\n",
    "t.assertEqual(len(testset_num), 8)\n",
    "t.assertIsInstance(testset_num[0], tuple)\n",
    "t.assertEqual(len(testset_num[0]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9ea1d020cf107709edff8fec2f2526b",
     "grade": false,
     "grade_id": "cell-008fcc0d21f07c3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_test() -> list:\n",
    "    \"\"\"\n",
    "    Classifies the test set using all the methods that were developed in this exercise sheet,\n",
    "    namely `decision`, `neighbor` and `NearestMeanClassifier`\n",
    "    \n",
    "    Returns:\n",
    "        list: a list of patient tuples containing all the datapoints that were classfied \n",
    "            the same by all methods, as well as the predicted labels\n",
    "            \n",
    "    Example:\n",
    "    >>> predict_test()\n",
    "    [(('yes', 22, 'poor'), 'less'),\n",
    "     (('yes', 21, 'poor'), 'less'),\n",
    "     (('no', 31, 'good'), 'more')]\n",
    "     \n",
    "    This example only shows how the output should look like. The values in the tuples \n",
    "    are completely made up\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    decisionset = gettest()\n",
    "    neighborset = gettrain()\n",
    "    classifier = build_and_train(gettrain_num())\n",
    "    classfy = gettest_num()\n",
    "    agreed_samples = []\n",
    "    for i in range(len(decisionset)):\n",
    "        if decision(decisionset[i]) == neighbor(decisionset[i],neighborset): #\"more\",\"less\"\n",
    "            prea = classifier.predict(decisionset[i])\n",
    "            if decision(decisionset[i]) == prea:\n",
    "                \n",
    "                 prediction = (decisionset[i],decision(decisionset[i]))\n",
    "                 agreed_samples.append(prediction)\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return agreed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4f46b1aff55116de6f13a4605510038",
     "grade": true,
     "grade_id": "cell-853c957eaaf81c28",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4356, 2.4624, 2.01, 1.1444, 0.0064, 1.0256, 2.0144, 1.3364, 1.0576, 2.0784000000000002, 2.16, 0.0324, 1.1296, 2.0004, 0.0036, 1.4624000000000001]\n",
      "0.0036\n",
      "(('yes', 18, 'poor'), 'less')\n",
      "[1.0064, 0.010000000000000002, 0.2304, 1.04, 2.25, 1.5476, 0.48999999999999994, 1.0, 1.1156, 0.09, 0.0324, 2.16, 1.0484, 0.36, 2.4096, 1.01]\n",
      "0.010000000000000002\n",
      "(('no', 55, 'good'), 'less')\n",
      "[1.3844, 0.4096, 0.0036, 1.1156, 2.0016, 1.04, 0.0256, 1.2916, 1.04, 0.0576, 0.1296, 2.0196, 1.1024, 0.0036, 2.01, 1.4096]\n",
      "0.0036\n",
      "(('no', 26, 'good'), 'less')\n",
      "(('no', 20, 'good'), 'less')\n",
      "[1.0324, 2.04, 2.1444, 1.01, 0.16000000000000003, 1.4096, 2.36, 1.01, 1.0576, 2.04, 2.0064, 0.09, 1.0144, 2.25, 0.2916, 1.04]\n",
      "0.09\n",
      "(('yes', 30, 'poor'), 'more')\n",
      "[0.0036, 1.0064, 1.25, 0.0484, 1.2704, 2.5776, 1.5184, 2.0004, 0.1296, 1.1024, 1.04, 1.1764, 2.0576, 1.3844, 1.4356, 0.0064]\n",
      "0.0036\n",
      "(('yes', 54, 'good'), 'less')\n",
      "[1.0144, 0.010000000000000002, 0.4624000000000001, 1.1600000000000001, 2.49, 1.8836, 0.81, 1.04, 1.2916, 0.25, 0.1444, 2.36, 1.1764, 0.6400000000000001, 2.7056, 1.01]\n",
      "0.010000000000000002\n",
      "(('no', 55, 'good'), 'less')\n",
      "[2.6084, 1.6400000000000001, 1.0484, 2.25, 1.04, 0.0016, 1.0, 0.48999999999999994, 2.1296, 1.1600000000000001, 1.2704, 1.09, 0.2304, 1.01, 1.0036, 2.64]\n",
      "0.0016\n",
      "(('no', 13, 'poor'), 'more')\n",
      "[1.5184, 0.5476, 0.0256, 1.1936, 2.0196, 1.01, 0.0036, 1.4096, 1.09, 0.11560000000000002, 0.2116, 2.0576, 1.1764, 0.0016, 2.0, 1.5476]\n",
      "0.0016\n",
      "(('no', 20, 'good'), 'less')\n",
      "[(('yes', 21, 'poor'), 'less'),\n",
      " (('no', 23, 'good'), 'less'),\n",
      " (('yes', 45, 'poor'), 'more'),\n",
      " (('no', 18, 'good'), 'less')]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "4 != 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b9b1e232e055>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertIsInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertIsInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertIsInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\unittest\\case.py\u001b[0m in \u001b[0;36massertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \"\"\"\n\u001b[0;32m    851\u001b[0m         \u001b[0massertion_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getAssertEqualityFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[0massertion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massertNotEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\unittest\\case.py\u001b[0m in \u001b[0;36m_baseAssertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[0mstandardMsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s != %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_common_shorten_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_formatMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardMsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfailureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massertEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 4 != 6"
     ]
    }
   ],
   "source": [
    "same_predictions = predict_test()\n",
    "pprint(same_predictions)\n",
    "t.assertIsInstance(same_predictions, list)\n",
    "t.assertEqual(len(same_predictions), 6)\n",
    "t.assertIsInstance(same_predictions[0], tuple)\n",
    "t.assertIsInstance(same_predictions[0][0], tuple)\n",
    "t.assertIsInstance(same_predictions[0][0][0], str)\n",
    "t.assertIsInstance(same_predictions[0][1], str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
